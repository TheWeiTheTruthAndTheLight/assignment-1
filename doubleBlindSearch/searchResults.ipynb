{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import functools\n",
    "import re\n",
    "from itertools import chain\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get(url, query):\n",
    "    quoted_query = quote_plus(query)\n",
    "    underscored_query = query.replace(' ', '_')\n",
    "    full_url = '{}?q={}'.format(url, quoted_query)\n",
    "    r = requests.get(full_url)\n",
    "    status = r.status_code\n",
    "    if status is 200:\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print('Error code: {}; URL: {}'.format(status, full_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def yahoo(query): return yahooParser(get('https://search.yahoo.com/search;', query))\n",
    "def yahooParser(soup):\n",
    "    matchURLsThatArentYahoosIP = re.compile(\"(?=^http.)(?!^http:\\/\\/98)\")\n",
    "    selectResultsTag           = lambda soup : soup.select(\"ol.searchCenterMiddle\")[0]\n",
    "    removeNewsAndSpecialLinks  = lambda soup : soup.select(\"div.wrapstar\")+soup.select(\"div.algo\")\n",
    "    selectSearchResults        = lambda soup : removeNewsAndSpecialLinks(selectResultsTag(soup))\n",
    "    removeInvalidURLs          = lambda url  : matchURLsThatArentYahoosIP.search(url)\n",
    "    selectLinkTag              = lambda div  : div.find_all('a', href=True)\n",
    "    selectLinkURL              = lambda link : link[\"href\"]\n",
    "    flatmap                    = lambda fun, lst : list(chain.from_iterable(map(fun,lst)))\n",
    "    \n",
    "    return list(filter(removeInvalidURLs,\n",
    "                map(selectLinkURL,\n",
    "                flatmap(selectLinkTag,\n",
    "                        selectSearchResults(soup)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def google(query): return googleParser(get('https://www.google.com/search', query))\n",
    "def googleParser(soup):\n",
    "    matchNonSpecialResults = re.compile('^(?!News for|Images for).*$')\n",
    "    selectResultTags       = lambda soup : soup.select('div#ires div.g h3.r a')\n",
    "    removeSpecialResults   = lambda tags : filter(lambda tag: matchNonSpecialResults.search(tag.text), tags)\n",
    "    selectLinkURL          = lambda link : link['href']\n",
    "    trimURL                = lambda url  : url.strip('/url?q=').split('&')[0]\n",
    "    \n",
    "    return list(map(trimURL,\n",
    "                map(selectLinkURL,\n",
    "                    removeSpecialResults(selectResultTags(soup)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bing(query): return bingParser(get('http://www.bing.com/search', query))\n",
    "def bingParser(soup): \n",
    "    return [t.h2.a['href'] for t in soup.find_all('li', 'b_algo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    return {\n",
    "        'Bing'  : bing(query),\n",
    "        'Google': google(query),\n",
    "        'Yahoo' : yahoo(query),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bing': ['http://www.speedtest.net/',\n",
       "  'http://www.thefreedictionary.com/test',\n",
       "  'http://www.test.com/',\n",
       "  'https://www.speakeasy.net/speedtest/',\n",
       "  'http://www.dictionary.com/browse/test',\n",
       "  'https://en.wikipedia.org/wiki/Test_(student_assessment)',\n",
       "  'http://www.merriam-webster.com/dictionary/test',\n",
       "  'https://en.wikipedia.org/wiki/Test',\n",
       "  'http://www.tests.com/'],\n",
       " 'Google': ['https://www.test.com/',\n",
       "  'http://www.speedtest.net/',\n",
       "  'https://en.wikipedia.org/wiki/Test',\n",
       "  'https://www.speakeasy.net/speedtest/',\n",
       "  'https://www.16personalities.com/free-personality-test',\n",
       "  'http://speedtest.xfinity.com/',\n",
       "  'http://www.realclearpolitics.com/video/2016/10/17/_youtuber_test_car_with_trump_stickers_looted_destroyed_by_black_youth.html',\n",
       "  'http://www.springer.com/statistics/journal/11749',\n",
       "  'https://implicit.harvard.edu/implicit/takeatest.html'],\n",
       " 'Yahoo': ['http://www.speedtest.net/',\n",
       "  'http://www.thefreedictionary.com/test',\n",
       "  'http://www.test.com/',\n",
       "  'https://www.speakeasy.net/speedtest/',\n",
       "  'http://www.dictionary.com/browse/test',\n",
       "  'https://en.wikipedia.org/wiki/Test_(student_assessment)',\n",
       "  'http://www.merriam-webster.com/dictionary/test',\n",
       "  'https://en.wikipedia.org/wiki/Test',\n",
       "  'http://www.tests.com/',\n",
       "  'http://www.queendom.com/tests/index.htm']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('test')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
